{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Data set, augmentation, and baseline\n",
    "## Goals:\n",
    "- Explore data\n",
    "- Augment data\n",
    "- Train a simple model and evaluate the effect of using augmented data\n",
    "\n",
    "\n",
    "In this exercise we are going to explore how augmented data can be used in training and testing.\n",
    "\n",
    "The code used in the exercise is based on the code already shown during the lecture. In this notebook you get the main code blocks to do the exercise. It helps to look at the code to get inspiration to solve the exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "In this execercise we will be working with a CT data set from lungs which are acompanied by a list of labels to tell if the image is healthy or malign. The image slices are stored in a (3D) numpy array and the labels in a pandas data frame. [Pandas](https://pandas.pydata.org/docs/) is a libray that helps you to store tables of data that are searchable and slicable depending on different criteria.\n",
    "\n",
    "__Note:__ Please uncompress the file ```ct_tiles.tif.zip``` before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = io.imread('ct_tiles.tif')\n",
    "labels = pd.read_csv('malignancy.csv')\n",
    "print('Image size: {0},{1},{2}'.format(imgs.shape[0],imgs.shape[1],imgs.shape[2]))\n",
    "print('Labels {0}'.format(labels.malignancy.count() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the first thing to do after loading the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: What can we observe in the label distribution?\n",
    "labels.malignancy.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.malignancy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels.malignancy.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: What can we observe in the data array?\n",
    "LABEL = 1\n",
    "r = slice(0,49) if LABEL == 1 else slice(-49,None)\n",
    "plt.figure(figsize=[25,25])\n",
    "for idx,tile in enumerate(imgs[r]) :\n",
    "    plt.subplot(7,7,idx+1)\n",
    "    plt.imshow(tile, cmap='gray') ;\n",
    "    i = idx if LABEL == 1 else -49 + idx\n",
    "    plt.title('Malignancy = {0}'.format(y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_sample_images(images, labels, n=25):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    indices = np.random.choice(len(images), n, replace=False)  # Randomly select n images\n",
    "    selected_images = images[indices]\n",
    "    selected_labels = labels[indices]\n",
    "    \n",
    "    grid_size = int(n ** 0.5)  # Create a square grid\n",
    "    for i, (img, label) in enumerate(zip(selected_images, selected_labels)):\n",
    "        plt.subplot(grid_size, grid_size, i + 1)\n",
    "        plt.imshow(img, cmap='gray')  # Use 'gray' for single-channel images\n",
    "        plt.title(f\"malignancy: {str(label)}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming your images are stored in `X` and labels in `y`\n",
    "plot_sample_images(imgs, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the data\n",
    "Let's create a data augmentation pipeline. The full range of readily available augmentations can be found here: https://github.com/albumentations-team/albumentations?tab=readme-ov-file#list-of-augmentations\n",
    "We will be working with some simple augmentations like:\n",
    "- rotation\n",
    "- translation\n",
    "- scaling\n",
    "- shear\n",
    "- flips\n",
    "- blurring\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# Define an augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # A.RandomBrightnessContrast(p=0.2),\n",
    "    A.RandomCrop(width=50, height=50),\n",
    "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=0, p=0.5),  # Width & height shift, zoom\n",
    "    A.Affine(shear=(-20, 20), p=0.5),  # Shear transformation\n",
    "    A.GaussianBlur(p=0.2),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),  # Normalize images\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WHich transformations do you see?\n",
    "im = imgs[0]\n",
    "transformed = transform(image=im)\n",
    "transformed_image = transformed[\"image\"]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(transformed_image, cmap='gray')\n",
    "plt.title(\"Transformed Image\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIven a set of images, plot the image and in the same row plot 4 augmentations of the image\n",
    "def plot_augmented_images(images, transform: A.Compose, n=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    indices = np.random.choice(len(images), n, replace=False)  # Randomly select n images\n",
    "    selected_images = images[indices]\n",
    "    \n",
    "    grid_size = int(n ** 0.5)  # Create a square grid\n",
    "    for i, img in enumerate(selected_images):\n",
    "        plt.subplot(n, 5, i * 5 + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        for j in range(4):\n",
    "            transformed = transform(image=img)\n",
    "            transformed_image = transformed[\"image\"]\n",
    "            plt.subplot(n, 5, i * 5 + j + 2)\n",
    "            plt.imshow(transformed_image, cmap='gray')\n",
    "            plt.title(f\"Augmented {j + 1}\")\n",
    "            plt.colorbar()\n",
    "            # plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming your images are stored in `X`\n",
    "plot_augmented_images(imgs, transform, n=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing baselines with augmented data\n",
    "From the lectures you learned that in order to compare the performance of an algorithm, you need a baseline algorithm. Previously, you heard about two algorithms:\n",
    "- Dummy classifier which uses the majority as prediction for any input data.\n",
    "- Nearest neighbor that uses the nearest feature as prediction.\n",
    "\n",
    "Below you get examples on the lung data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dc = DummyClassifier(strategy='most_frequent')\n",
    "dc.fit(imgs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dc.predict(imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate performance? Metrics:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- F1 score\n",
    "- ...\n",
    "- Quite comprehensive list: https://scikit-learn.org/stable/api/sklearn.metrics.html\n",
    "Use case dependent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - y.sum() / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Why do we reshape the images? What is the resulting shape?\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh_class = KNeighborsClassifier(n_neighbors=1)\n",
    "reshaped_imgs = imgs.reshape(imgs.shape[0], -1)\n",
    "neigh_class.fit(reshaped_imgs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a few images\n",
    "preds = neigh_class.predict(reshaped_imgs)\n",
    "plt.hist(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Stolen from: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = neigh_class.predict(reshaped_imgs)\n",
    "ax1 = print_confusion_matrix(confusion_matrix(y, pred_values), class_names=range(2))\n",
    "ax1.set_title('Accuracy: {:2.2%}'.format(accuracy_score(y, pred_values)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why did we get perfect accuracy? \n",
    "## What happens if we use K!=1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Evaluate the nearest neighbour baseline \"properly\" in this notebook.\n",
    "Complete the functions in `tasks.py` and pass the tests. You will have to:\n",
    "2. Create a subset of the original datasets with 500 images. Create an augmented data set of 2500 images from the selected subset. Pay attention to obtaining a representative balance between healthy and malign samples. The augmented images should be of size 64,64.\n",
    "3. Fit a KNNs classifier using \n",
    "    1. the original subset of 500 data samples. You should achieve >60% accuracy.\n",
    "    2. the augmented dataset. You should achieve >70% accuracy.\n",
    "    > Note: You will have to play with the number, type and hyperparameters of the augmentations and the kNN classifier.\n",
    "    > Note: You will have to implement the functions to train, predict and evaluate the kNN model.\n",
    "4. Compare the performance using the confusion matrix. Plot it on this notebook.\n",
    "\n",
    "> Tip: Solve each of the tasks first on the notebook, so it is easier to see the input and output of the functions. Check the file `test_exercise2.py` and the docstrings of each function to get more information on how to implement them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
